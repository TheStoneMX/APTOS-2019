{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this kernel we are going to use ImageDataGenerator to load images in batches of 16, and adding augmentation.\n",
    "* *CROPPING IMAGE* : We will also use image cropping to crop the extra black part in the images in the training data.\n",
    "* We will use the resnet50 model and then train it exclusively for our train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images', 'train_new', 'train_images']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"./input/aptos2019-blindness-detection/\"))\n",
    "from keras.applications import ResNet50, VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import csv\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D\n",
    "from keras.layers import Concatenate, Multiply, Dropout, Subtract, Lambda, Flatten\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import resnet50\n",
    "from keras.applications import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = \"./input/train.csv\"\n",
    "test_csv = \"./input/test.csv\"\n",
    "train_dir = \"./input/aptos2019-blindness-detection/train_images/\"\n",
    "test_dir = \"./input/aptos2019-blindness-detection/test_images/\"\n",
    "# size = 256,256 # input image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function defined below takes the dataframe of training data as an argument and return two dataframes, one for Training and one for Validation. \n",
    "* Need of this function : we are using image data generator with flow_from_dataframe and 10% validation split so if we use same ImageDataGenerator for training and validation data generation it will also augment the validation data, thus we will define seperate dataframes for training and validation data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = df[\"id_code\"].values.tolist()\n",
    "labels = df[\"diagnosis\"].values.tolist()\n",
    "\n",
    "for i in range(len(image_ids)):\n",
    "    imgname = image_ids[i]\n",
    "    newname = str(imgname) + \".png\"\n",
    "    image_ids[i] = newname\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    new_name = labels[i]\n",
    "    newname = str(new_name)\n",
    "    labels[i] = newname    \n",
    "# x_train, x_val, y_train, y_val = train_test_split(image_ids, labels, test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'filename': image_ids,\n",
    "    'label': labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(image_ids, labels, test_size = 0.25)\n",
    "train_df, validation_df = train_test_split(df, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              filename label\n",
      "462   207a580de0ea.png     2\n",
      "3204  df3adfd6ba36.png     2\n",
      "328   1891698febce.png     0\n",
      "1397  61c667663f2f.png     0\n",
      "2069  913b1890ed1e.png     2\n",
      "...                ...   ...\n",
      "1130  4f6abc40c72d.png     0\n",
      "1294  5a091e8cd95c.png     1\n",
      "860   3dfc50108072.png     2\n",
      "3507  f47a2a4a0411.png     1\n",
      "3174  dcc6c0ad5cad.png     0\n",
      "\n",
      "[2563 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2563, 2)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_num = len(train_df)\n",
    "validation_num = len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_image_generator(generator, \n",
    "                        df, \n",
    "                        directory, \n",
    "                        batch_size,\n",
    "                        x_col = 'filename', \n",
    "                        y_col = None, \n",
    "                        model = None, \n",
    "                        shuffle = False,\n",
    "                        img_size1 = (224, 224), \n",
    "                        img_size2 = (299,299)):\n",
    "    \n",
    "    gen1 = generator.flow_from_dataframe(\n",
    "        df,\n",
    "        directory,\n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        target_size = img_size1,\n",
    "#         class_mode = model,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = 1)\n",
    "    \n",
    "    gen2 = generator.flow_from_dataframe(\n",
    "        df,\n",
    "        directory,\n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        target_size = img_size2,\n",
    "#         class_mode = model,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        seed = 1)\n",
    "    \n",
    "    while True:\n",
    "        X1i = gen1.next()\n",
    "        X2i = gen2.next()\n",
    "     \n",
    "        if y_col:\n",
    "            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n",
    "        else:\n",
    "            yield [X1i, X2i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add data_augmentation\n",
    "train_aug_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "train_generator = two_image_generator(train_aug_datagen, \n",
    "                                      train_df, \n",
    "                                      './input/train/',\n",
    "                                      batch_size = batch_size, \n",
    "                                      y_col = 'label',\n",
    "                                      model = 'None', \n",
    "                                      shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = two_image_generator(validation_datagen, \n",
    "                                           validation_df,\n",
    "                                           './input/train/', \n",
    "                                           batch_size = batch_size,\n",
    "                                           y_col = 'label',\n",
    "                                           model = 'None', \n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.DataFrame({\"id_code\":x_train, \"diagnosis\":y_train})\n",
    "\n",
    "# df_val = pd.DataFrame({\"id_code\":x_val, \"diagnosis\":y_val})\n",
    "\n",
    "# df_train[\"diagnosis\"] = df_train[\"diagnosis\"].astype('str')\n",
    "\n",
    "# df_val[\"diagnosis\"] = df_val[\"diagnosis\"].astype('str')\n",
    "\n",
    "# print(\"Length of Training Data :\",len(df_train))\n",
    "# print(\"Length of Validation Data :\",len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROPPING FUNCTION :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(MODEL, img_size, lambda_fun = None):\n",
    "\n",
    "    inp = Input(shape = (img_size[0], img_size[1], 3))\n",
    "    x = inp\n",
    "    if lambda_fun:\n",
    "        x = Lambda(lambda_fun)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n",
    "        \n",
    "    model = Model(inp, base_model.output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_base_model(vgg16.VGG16, (224, 224), vgg16.preprocess_input)\n",
    "model2 = create_base_model(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)\n",
    "model3 = create_base_model(inception_v3.InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "\n",
    "model1.trainable = False\n",
    "model2.trainable = False\n",
    "model3.trainable = False\n",
    "\n",
    "inpA = Input(shape = (224, 224, 3))\n",
    "inpB = Input(shape = (299, 299, 3))\n",
    "\n",
    "out1 = model1(inpA)\n",
    "out2 = model2(inpA)\n",
    "out3 = model3(inpB)\n",
    "\n",
    "x = Concatenate()([out1, out2, out3]) \n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model([inpA, inpB], x)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=2e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"pretained-models_original-weights-improvement-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1,  patience=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer=opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel helped me choose the model parameters, and callbacks - [APTOS Blindness Detection - EDA and Keras ResNet50](https://www.kaggle.com/dimitreoliveira/aptos-blindness-detection-eda-and-keras-resnet50?scriptVersionId=16639594)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need a generator that yields something of the form **([x1, x2], y)** So you need to write your own generator, for which you can reuse the original ImageDataGenerator for one or more input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/.local/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1099 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "/home/oscar/.local/lib/python3.6/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 2563 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_5 to have shape (1,) but got array with shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-d457a8504301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [mc, es])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_5 to have shape (1,) but got array with shape (0,)"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = train_num // batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_num // batch_size,\n",
    "    verbose = 1,\n",
    "    callbacks = [mc, es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_orig = pd.read_csv(test_csv)\n",
    "\n",
    "def process_test_df(test_df):\n",
    "    test_ids = test_df[\"id_code\"].values.tolist()\n",
    "    for i in range(len(test_ids)):\n",
    "        imgname = test_ids[i]\n",
    "        newname = str(imgname) + \".png\"\n",
    "        test_ids[i] = newname\n",
    "    test_df[\"id_code\"] = test_ids\n",
    "    return test_df\n",
    "\n",
    "test_df = process_test_df(test_df_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data Generator :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = test_aug.flow_from_dataframe(dataframe = test_df, \n",
    "                                              directory = test_dir,\n",
    "                                              x_col = \"id_code\",\n",
    "                                              batch_size = 1,\n",
    "                                              target_size = (256,256),\n",
    "                                              shuffle = False,\n",
    "                                              class_mode = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predprobs = model.predict_generator(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in predprobs:\n",
    "    predictions.append(np.argmax(i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_orig[\"diagnosis\"] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_orig.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
